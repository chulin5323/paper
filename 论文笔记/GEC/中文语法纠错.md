# 中文语法纠错

## 进展

|                             论文                             | 会议/期刊 | 类型 |                           主要思想                           |                     代码                     |
| :----------------------------------------------------------: | :-------: | :--: | :----------------------------------------------------------: | :------------------------------------------: |
| [DR-CSC](D:\learning\论文\GEC\【2023 EMNLP】A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for.pdf) [ProTEC](D:\learning\论文\GEC\【2023 2】Progressive Multi-task Learning Framework for Chinese Text Error Correction.pdf) |   EMNLP   | CSC  | （非自回归方法）  多任务训练：detection、reasoning、searching，作为模块可用于其它CSC模型中 | [DR-CSC](https://github.com/THUKElab/DR-CSC) |
|                                                              |           |      |                                                              |                      -                       |
|                                                              |           |      |                                                              |                                              |

## 结果

> 按照correction **P R F**以此呈现

|                             论文                             |                SIGHAN13                |                SIGHAN14                |                SIGHAN15                |
| :----------------------------------------------------------: | :------------------------------------: | :------------------------------------: | :------------------------------------: |
| [DR-CSC](D:\learning\论文\GEC\【2023 EMNLP】A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for.pdf) [ProTEC](D:\learning\论文\GEC\【2023 2】Progressive Multi-task Learning Framework for Chinese Text Error Correction.pdf) | （SCOPE + DR-CSC）87.7 \| 83.0 \| 85.3 | （SCOPE + DR-CSC）69.3 \| 72.3 \| 70.7 | （SCOPE + DR-CSC）87.0 \| 91.9 \| 89.4 |
|                                                              |                                        |                                        |                                        |
|                                                              |                                        |                                        |                                        |
|                                                              |                                        |                                        |                                        |



## 背景

### 错误类型

> 处理难度：字词错误 < 句法错误 < 语义错误

- #### 字词错误

  - 同音词——米月传$\longrightarrow$芈月传；渡假$\longrightarrow$度假

  - 模糊音——胡建$\longrightarrow$福建；

  - 形近词——go语音$\longrightarrow$go语言；
  - 混拼音——xingfu$\longrightarrow$幸福，sz$\longrightarrow$深圳；
  - 字词缺失——自然语处理$\longrightarrow$自然语言处理；
  - 字词冗余——自然语言处处理$\longrightarrow$自然语言处理；

- #### 句法错误

  - 字词乱序——首个开发的空间站$\longrightarrow$开发的首个空间站；
  - 搭配不当——生活水平改善$\longrightarrow$生活水平提高；
  - 结构混乱——靠的是...取得的$\longrightarrow$靠的是.... / 是...取得的；
  - 知识错误——中国的首都是南京$\longrightarrow$中国的首都是北京；

- #### 语义错误

  - 表意不明——让小王本月15日前去汇报$\longrightarrow$前 或 前去；
  - 逻辑错误——防止这类事故不再发生$\longrightarrow$防止这类事故再发生。

## 类型

- 中文拼写纠错任务——Chinese Spelling Check（CSC）
  - 该任务一般不涉及添加或者删除字词，所以**输入输出序列一般等长**；
  - 数据集：SIGHAN13/14/15；
  - CSC任务一般被建模成字级别序列标注任务；
- 中文语法纠错任务——Chinese Grammatical Error Correction（CGEC）
  - 需要添加或者删除字词，一般**输入输出序列不等长**；
  - 数据集：NLPCC18-Task2、CGED；
  - 思路：
    - **检错-排序-召回**（工业界常用）
    - **端到端纠错**
      - **序列到序列**（sequence-to-sequence）模型——视为翻译任务（自回归生成的特点擅长于解决调序等错误；）
      - **序列到编辑**（sequence-to-edit）模型——通过增、删、改进行纠错，速度快，效果较好
- 中文语义错误——Chinese semantic error

## 纠错思路

1. #### 多模型pipeline

> 主要分为三个步骤：**错误检测、候选召回、候选排序**。（百度）

**（1）错误检测**

> 错误检测的目标是识别输入句子中可能存在的问题，定位到错误词的位置。

a. 基于规则

- 拼音匹配检测: 抽取ngram级别的拼音，构建实体词与拼音映射词表，将抽取的拼音映射到实体词，比较和原词是否一致。
- 拼音编辑距离检测: 同上，但是拼音映射的实体词并不一定要完全同拼音，一定编辑距离之内即可。
- 单双向2-gram检测: 统计大规模语料中2gram的频率，检测适合句子中的2-gram小于一定频次即识别为错误。
- 困惑集：在SIGHAN7 Bake-off 2013中文拼写检查任务中，组织者提供了六种混淆集：4组语音相似的字符（音近字）和2组视觉上相似的字符（形近字）

b.语言模型

使用LM预测下一个字（或上一个字），如果真实字不在预测的topk内，即识别为错误。LM从**规则到统计模型到gpt**皆可。

另外一种同思想的方法是bert的遮蔽语言模型，将当前词用mask符号代替，然后做预测，若真实字不在topk内即为错。

> 目前在有embedding的纠错方案中，重新进行预训练并加入拼音和字形embedding已经成为主流方案。

c.序列标注 or PLM

**（2）候选召回**

> 对识别出的错误进行纠正，需结合**历史错误行为**，以及**音形**等特征召回纠错候选。

a.离线候选挖掘

b.在线候选排序

- 基于规则
  - 近音候选词召回、字音编辑距离召回
- 语言模型
  - 简单地利用LM或者ptm计算错误词可能的topk正确答案。

**（3）候选排序**

> 由于纠错的正确结果具有唯一性，如何在召回的纠错候选中将正确的结果排在第一位。

a.粗排序

候选召回模块得到的候选词数量庞大，逐一通过复杂模型计算替换概率将引入较大的时间损耗，因此在精排序前需要进行一定粗排序，从而通过简单的算法来过滤掉部分明显错误的答案。

b.精排序

2. #### 端到端

> 将从原始“错误句子”到修正后“正确句子”的处理过程，看作是一个机器翻译的问题，即将错误的句子翻译成正确的句子。

## 数据集

### 中文数据集：

- [NLPTEA-2020](https://aclanthology.org/2020.nlptea-1.4.pdf) 
- [NLPCC-2018](http://tcci.ccf.org.cn/conference/2018/papers/EV11.pdf) 
- [MuCGEC](https://arxiv.org/pdf/2204.10994.pdf) 

![](D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_1.png)

## 评价指标

### MaxMatch（$M^2$）

> 参考资料：[论文](https://aclanthology.org/N12-1067.pdf)   [F-$\beta$ score](https://blog.csdn.net/Libo_Learner/article/details/83615715)  

- MaxMatch是一个referenced-based的评价指标+，本质上是$F_\beta$分数的计算

    - TP：假设编辑与参考编辑匹配
    - FP：假设编辑与参考编辑不匹配（参考编辑与原句中的词相同）
    - FN：参考编辑与假设编辑不匹配（参考编辑与原巨中的词不同）

    ![](D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_2.png)

    ![](D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_3.png)

    > 常用$\beta$值为0.5，表示precision的权重是recall的两倍。
    >
    > $\beta$的值越大表示recall的权重越大，反之则越小。这是由于在原始定义中，将recall乘以了$\beta$倍。

    <img src="D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_4.png"  />

- 当一个句子有多个参考编辑时，$M^2$分数会遍历每一个参考编辑，并选择性能最好的参考编辑。

### ERRANT

> 参考资料：[论文](https://api.repository.cam.ac.uk/server/api/core/bitstreams/6221f16a-33cf-4e57-8bf1-f606c355ef68/content) 

- ERRANT是一个referenced-based的评价指标，与$M^2$分数类似，但不同之处在于，ERRANT还能计算**错误类型分数（error types scores）**。
- 该指标对于详细的系统分析很有价值，比如系统A在总体纠错性能上超过系统B，但系统B在某些错误类型上的纠错效果好于系统A，那么可以利用这个信息提升系统A的性能。
- 该方法**不支持中文**。(该方法的中文版本为[ChERRANT](https://github.com/HillZhang1999/MuCGEC?tab=readme-ov-file)) 

### GLEU

> 参考资料：[论文](https://aclanthology.org/P15-2097.pdf) [BLEU](https://zhuanlan.zhihu.com/p/350596071) [n-grams](https://zhuanlan.zhihu.com/p/32829048)

- GLEU是一个referenced-based的评价指标，该方法不需要明确的编辑注释，而仅需要**正确的参考句子**即可。
- 该方法对hypothesis n-grams和reference重叠但与原始文本不重叠的部分给予**奖励**，对hypothesis n-grams与原始文本重叠但与reference不重叠的部分给予**惩罚**。
- 假设原始句子为：$O=\{o_1,...,o_k\}$，模型输出假设为：$H=\{h_1,...,h_k\}$，参考句子为：$R=\{r_1,...,r_k\}$，其中，$o_i,r_i,h_i$分别表示句子中n-grams序列（GLEU中默认$n=4$）。则精确率$p_n$可以通过考虑奖励和惩罚来进行计算：

<img src="D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_5.png" style="zoom: 67%;" />

与BLEU类似，GLEU也存在一个Brevity Penalty（BP）来对hypotheses比reference短的情况进行惩罚：

<img src="D:\learning\论文\论文笔记\GEC\图片\中文语法纠错_6.png" style="zoom:67%;" />

