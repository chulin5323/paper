# N-grams

> [参考资料 ](https://zhuanlan.zhihu.com/p/32829048)
>
> N-Gram是一种基于统计语言模型的算法。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。
>
> 每一个字节片段称为gram，对所有gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成**关键gram列表**，也就是这个文本的向量特征空间，列表中的每一种gram就是一个特征向量维度。
>
> 该模型基于这样一种假设，第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。

## 一、概念

- 根据马尔科夫链假设，当前词的出现与前n-1个词相关：

$$
p(w_1,w_2,...,w_m)=p(w_i|w_{n-i+1},..,w_{i-1})
$$



当n=1，2，3时，分别得出一元模型（unigram model）：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_1.png)

二元模型（bigram model）：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_2.png)

三元模型（trigram model）：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_3.png)

- 根据贝叶斯定理，将概率转化为词频相乘：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_4.png)

> 其中，$C(\cdot)$为词库中的词频。

## 二、例子

假设现在有一个语料库，统计了下面的一些词出现的数量：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_5.png)

下面的这些概率值作为已知条件：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_6.png)

由bigram进行计数之后的结果为：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_7.png)

其中第一行，第二列 表示给定前一个词是 “i” 时，当前词为“want”的情况一共出现了827次。据此，可以算得相应的频率分布表如下：

![](D:\learning\论文\论文笔记\NLP\图片\n-grams_8.png)

> 以表中的p(eat|i)=0.0036这个概率值讲解，从表一得出“i”一共出现了2533次，而其后出现eat的次数一共有9次，$p(eat|i)=p(eat,i)/p(i)=count(i,eat)/count(i)=9/2533 = 0.0036$

# BLEU

> [论文](https://aclanthology.org/P02-1040.pdf) [参考链接](https://zhuanlan.zhihu.com/p/350596071) 
>
> BLEU（Bilingual Evaluation Understudy），即双语评估替补。所谓替补就是代替人类来评估机器翻译的每一个输出结果。Bleu score 所做的，给定一个机器生成的翻译，自动计算一个分数，衡量机器翻译的好坏。取值范围是[0, 1],越接近1,表明翻译质量越好。
>
> 本质上是**相似度**的计算。

## 一、概念

- 公式

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_1.png)

其中，$BP$是简短惩罚因子，惩罚一句话的长度过短，防止训练结果倾向短句的现象，其表达式为：

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_2.png)

> **BP 的作用在于，如果输出一个非常短的句子，那很容易得到 Bleu score 的高分，所以我们要防止这个情况的出现**  
>
> **BP 在机器翻译长度大于人类翻译长度的时候取值为 1，否则产生惩罚**  

$P_n$，是基于n-gram的精确度，其表达公式为：

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_3.png)

## 二、例子

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_4.png)

- Reference 1 和 Reference 2两句都是很不错的人工进行的翻译，那么如何利用这两句话对其他机器翻译得出的结果进行评估？
- 一般衡量机器翻译输出质量的方法之一是观察输出结果的每一个词，看其是否出现在参考（也就是人工翻译结果）中，这被称为是机器翻译的精确度。而这样计算得出的精确度很快就能被一个反例打破，那就是：**the the the the the the the.** 

评估的两种方法：

1.  **Precision**（精确度）：看机器翻译的每一个词，有没有在翻译参考中出现。在上面的案例中，虽然全是 the 是一个非常糟糕的翻译结果，但是 Precision = 7/7 = 1（该衡量方法不靠谱）
2. **Modified precision**：设定最高权重上限，比如第一句翻译参考中，the 出现了 2 次；第二句中， the 出现了 1 次，那权重上限就是 2。这样 Modified precision = 2/7.

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_5.png)

**关注词组的BLEU**

1. 这个例子中，一共有 5 种 bigrams 的组合
2. 分别数一下出现的次数
3. 分别数一下在翻译参考中出现的次数
4. 最终 modified bigram precision = 4/6

![](D:\learning\论文\论文笔记\NLP\图片\BLEU_6.png)

可以将其公式化，这里的 $P_1$ 下标 1 表示的是 一元词组，推广到 n 元词组。

如果机器翻译的结果和参考翻译中的某一句完全相同，那么 $P_1 = P_2 = … = P_n = 1$
也有可能通过某种组合各个参考翻译得到结果为 1。