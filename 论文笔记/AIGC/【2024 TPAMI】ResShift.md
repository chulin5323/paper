# Efficient Diffusion Model for Image Restoration by Residual Shifting

> 这篇文章主要解决了图像恢复（Image Restoration, IR）领域中的一个关键挑战：如何提高基于扩散模型的图像恢复方法的推理速度。具体来说，文章提出了一种新的高效扩散模型，用于图像恢复任务，该模型显著减少了所需的扩散步骤数量，从而加快了推理过程。这种方法避免了在推理期间需要进行后加速处理，从而避免了与后加速相关的性能下降问题。通过在**高质量（HQ）和低质量（LQ）图像之间通过残差转移来建立马尔可夫链**，文章提出的方法大幅提高了转换效率，并设计了一个精心制定的噪声计划，以灵活控制扩散过程中的残差转移速度和噪声强度。实验结果表明，该方法在图像超分辨率、图像修复、盲面孔恢复和图像去模糊等四个经典的图像恢复任务上，即使仅使用四个采样步骤，也能实现与当前最先进方法相当或更优的性能。

## 相关研究及缺陷

1. **基于扩散模型的图像恢复方法**：
   - **缺陷**：这些方法通常需要执行数百甚至数千个采样步骤，导致推理速度慢。尽管有一些加速采样技术，但它们往往会牺牲性能，导致恢复出的图像过于模糊。

2. **直接将低质量图像作为条件输入到扩散模型的方法**：
   - **缺陷**：这些方法需要针对特定的图像恢复任务重新训练模型，这不仅耗时而且不够灵活。

3. **使用预训练的无条件扩散模型来处理图像恢复问题的方法**：
   - **缺陷**：这些方法在反向采样过程中需要在每次迭代中结合退化模型，这限制了它们在实际应用中的效率，并且通常需要大量的采样步骤。

4. **最近的进步**：
   - **缺陷**：尽管最近的研究引入了加速技术来减少采样步骤，但这些方法通常会导致性能显著下降，表现为过度平滑的结果。

## 解决的问题

文章通过提出一种新的高效扩散模型来解决现有图像恢复方法中的缺陷：

1. **减少扩散步骤**：
   - 文章提出的模型通过建立一个**从高质量（HQ）图像到低质量（LQ）图像的马尔可夫链**，而不是从高斯白噪声开始，有效减少了所需的扩散步骤。这种方法直接针对图像恢复任务设计，减少了从噪声到图像的漫长转换过程。
2. **残差转移**：
   - 通过设计一个转换核，逐步在HQ和LQ图像对之间转移残差信息。这种方法快速地在有限的步骤内传递残差信息，提高了转换效率。
3. **灵活的噪声scheduler**：
   - 文章设计了一个精心制定的噪声scheduler，通过超参数κ和转移序列${η_t}$来控制扩散过程中的**噪声强度**和**残差转移速度**。这种设计提供了在恢复图像的保真度和真实感之间进行平衡的机制。
4. **感知正则化**：
   - 为了进一步减少扩散步骤，文章引入了感知正则化，通过结合传统的证据下界（ELBO）和感知损失（如LPIPS），在保持性能的同时减少了所需的采样步骤。
5. **Swin Transformer块**：
   - 为了提高模型对不同分辨率图像的适应性，文章提出用Swin Transformer块替换传统的自注意力层。Swin Transformer在局部窗口内计算注意力图，因此不受图像分辨率的影响，解决了自注意力层在处理不同分辨率图像时出现的模糊问题。

## 方法

<img src="D:\learning\paper\论文笔记\AIGC\fig\ResShift_1.png" style="zoom:80%;" />

1. **马尔可夫链（Markov chain）**：
   - 通过建立一个马尔可夫链来促进高质量（HQ）图像和低质量（LQ）图像之间的转换，从而实现图像恢复。
2. **残差转移（Residual Shifting）**：
   - 设计了一个转换核，逐步在HQ和LQ图像对之间转移残差信息，以快速传递残差信息。
3. **噪声计划（Noise Schedule）**：
   - 通过超参数κ和转移序列${η_t}$来控制扩散过程中的噪声强度和残差转移速度，提供了在恢复图像的保真度和真实感之间进行平衡的机制。
4. **感知正则化（Perceptual Regularization）**：
   - 引入感知正则化，结合传统的证据下界（ELBO）和感知损失（如LPIPS），以减少所需的采样步骤，同时保持或提高恢复图像的性能。
5. **Swin Transformer块**：
   - 用Swin Transformer块替换传统的自注意力层，以提高模型对不同分辨率图像的适应性，解决自注意力层在处理不同分辨率图像时出现的模糊问题。
6. **优化目标（Optimization Objective）**：
   - 通过最小化负ELBO（Evidence Lower Bound）来优化模型参数，简化了训练过程中的目标函数。
7. **扩展到潜在空间（Extension to Latent Space）**：
   - 为了减轻训练中的计算负担，文章提出将模型可选地移动到VQGAN的潜在空间中，通过压缩原始图像来减少空间维度。
